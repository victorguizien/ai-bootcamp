{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97784da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Setup\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(\"LLM ready\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zr93zve5u6",
   "metadata": {},
   "source": [
    "## Step 1: Load the raw data and see what's messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lrbgoq7wk8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (96, 7)\n",
      "\n",
      "Missing values:\n",
      "name            0\n",
      "age             1\n",
      "salary          4\n",
      "department      0\n",
      "experience      1\n",
      "city            8\n",
      "employee_id    92\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>department</th>\n",
       "      <th>experience</th>\n",
       "      <th>city</th>\n",
       "      <th>employee_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Doe</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>Sales</td>\n",
       "      <td>3.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>E001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>34.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob Johnson</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IT</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice Brown</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charlie Davis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Lily Ward</td>\n",
       "      <td>35.0</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>HR</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Mark Cole</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>Sales</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Portland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Nora Moon</td>\n",
       "      <td>39.0</td>\n",
       "      <td>69000.0</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Omar Lane</td>\n",
       "      <td>26.0</td>\n",
       "      <td>47000.0</td>\n",
       "      <td>IT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Penny Shah</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>HR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name   age   salary department  experience      city employee_id\n",
       "0        John Doe  28.0  50000.0      Sales         3.0  New York        E001\n",
       "1      Jane Smith  34.0  65000.0  Marketing         7.0    Boston         NaN\n",
       "2     Bob Johnson  45.0      NaN         IT        15.0       NaN         NaN\n",
       "3     Alice Brown  29.0  48000.0      Sales         2.0   Chicago         NaN\n",
       "4   Charlie Davis   NaN      NaN         HR         NaN       NaN         NaN\n",
       "..            ...   ...      ...        ...         ...       ...         ...\n",
       "91      Lily Ward  35.0  62000.0         HR         9.0    Austin         NaN\n",
       "92      Mark Cole  30.0  56000.0      Sales         6.0  Portland         NaN\n",
       "93      Nora Moon  39.0  69000.0  Marketing        13.0   Phoenix         NaN\n",
       "94      Omar Lane  26.0  47000.0         IT         2.0    Dallas         NaN\n",
       "95     Penny Shah  32.0  58000.0         HR         7.0   Atlanta         NaN\n",
       "\n",
       "[96 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../data/sample_data.csv\")\n",
    "print(f\"Shape: {df_raw.shape}\")\n",
    "print(f\"\\nMissing values:\\n{df_raw.isna().sum()}\")\n",
    "print(f\"\\nDuplicate rows: {df_raw.duplicated().sum()}\")\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cmhr4gdvrt",
   "metadata": {},
   "source": [
    "## Step 2: Build the summary the LLM sees\n",
    "This is what `get_dataframe_summary()` produces — the LLM's only view of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "keudfzd91i",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Column Data Types:\n",
      "      name: object\n",
      "      age: float64\n",
      "      salary: float64\n",
      "      department: object\n",
      "      experience: float64\n",
      "      city: object\n",
      "      employee_id: object\n",
      "\n",
      "    Missing Value Percentage:\n",
      "      employee_id: 95.83%\n",
      "      city: 8.33%\n",
      "      salary: 4.17%\n",
      "      age: 1.04%\n",
      "      experience: 1.04%\n",
      "      name: 0.00%\n",
      "      department: 0.00%\n",
      "\n",
      "    Outlier Stats (numerical cols):\n",
      "      age: Lower Bound: 3.05, Upper Bound: 64.25\n",
      "      salary: Lower Bound: 7375.00, Upper Bound: 109175.00\n",
      "      experience: Lower Bound: -18.70, Upper Bound: 35.70\n",
      "\n",
      "    String Column Samples:\n",
      "      name: ['John Doe', 'Jane Smith', 'Bob Johnson', 'Alice Brown', 'Charlie Davis', 'Emma Wilson', 'Frank Miller', 'Grace Lee', 'Henry Taylor', 'Ivy Chen']\n",
      "      department: ['Sales', 'Marketing', 'IT', 'HR']\n",
      "      city: ['New York', 'Boston', 'Chicago', 'Seattle', 'Austin', 'Denver', 'Portland', 'Miami', 'Phoenix', 'Atlanta']\n",
      "      employee_id: ['E001', 'E007', 'E019']\n"
     ]
    }
   ],
   "source": [
    "from utils import get_dataframe_summary\n",
    "\n",
    "summary = get_dataframe_summary(df_raw, indent=4)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4tkhb1wmp0w",
   "metadata": {},
   "source": [
    "## Step 3: Build the prompt and send it to the LLM\n",
    "This is the actual prompt the model receives. It asks for a Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89fd7c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_name=\"data_cleaner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wxmq41y4wya",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DATA_CLEANING_PROMPT_TEMPLATE\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=DATA_CLEANING_PROMPT_TEMPLATE,\n",
    "    input_variables=[\"user_instructions\", \"all_datasets_summary\", \"function_name\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "124ca51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a Data Cleaning Agent. Create a data_cleaner() function to clean the data.\n",
      "\n",
      "Basic Cleaning Steps to implement:\n",
      "1. Remove columns with more than 40% missing values\n",
      "2. Impute missing values (mean for numeric, mode for categorical)\n",
      "3. Remove duplicate rows\n",
      "4. Remove outliers (numerical cols) outside of p05 and p95\n",
      "5. Normalize string columns (strip whitespace, normalize casing)\n",
      "\n",
      "User Instructions:\n",
      "Follow the basic cleaning steps.\n",
      "\n",
      "Dataset Summary:\n",
      "    Column Data Types:\n",
      "      name: object\n",
      "      age: float64\n",
      "      salary: float64\n",
      "      department: object\n",
      "      experience: float64\n",
      "      city: object\n",
      "      employee_id: object\n",
      "\n",
      "    Missing Value Percentage:\n",
      "      employee_id: 95.83%\n",
      "      city: 8.33%\n",
      "      salary: 4.17%\n",
      "      age: 1.04%\n",
      "      experience: 1.04%\n",
      "      name: 0.00%\n",
      "      department: 0.00%\n",
      "\n",
      "    Outlier Stats (numerical cols):\n",
      "      age: Lower Bound: 3.05, Upper Bound: 64.25\n",
      "      salary: Lower Bound: 7375.00, Upper Bound: 109175.00\n",
      "      experience: Lower Bound: -18.70, Upper Bound: 35.70\n",
      "\n",
      "    String Column Samples:\n",
      "      name: ['John Doe', 'Jane Smith', 'Bob Johnson', 'Alice Brown', 'Charlie Davis', 'Emma Wilson', 'Frank Miller', 'Grace Lee', 'Henry Taylor', 'Ivy Chen']\n",
      "      department: ['Sales', 'Marketing', 'IT', 'HR']\n",
      "      city: ['New York', 'Boston', 'Chicago', 'Seattle', 'Austin', 'Denver', 'Portland', 'Miami', 'Phoenix', 'Atlanta']\n",
      "      employee_id: ['E001', 'E007', 'E019']\n",
      "\n",
      "Return Python code in ```python``` format with a single function:\n",
      "\n",
      "def data_cleaner(data_raw):\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    # Your cleaning code here\n",
      "    return data_cleaned\n",
      "\n",
      "Important: Ensure fit_transform() outputs are flattened with .ravel() when assigning to DataFrame columns.\n"
     ]
    }
   ],
   "source": [
    "filled_prompt = prompt.format(\n",
    "    user_instructions=\"Follow the basic cleaning steps.\",\n",
    "    all_datasets_summary=summary,\n",
    "    function_name=function_name\n",
    ")\n",
    "print(filled_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l3nolk91f8",
   "metadata": {},
   "source": [
    "## Step 4: Call the LLM and parse the Python code out\n",
    "The LCEL chain `prompt | llm | parser` does this in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf781af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q18rk73btcq",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import PythonOutputParser\n",
    "\n",
    "chain = prompt | llm | PythonOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generated_code = chain.invoke({\n",
    "    \"user_instructions\": \"Follow the basic cleaning steps.\",\n",
    "    \"all_datasets_summary\": summary,\n",
    "})\n",
    "\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j53eobdq2y",
   "metadata": {},
   "source": [
    "## Step 5: Execute the generated code with `exec()`\n",
    "This is what `execute_agent_code()` does under the hood — runs the code string, extracts the function, and calls it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l2d59rtc8ue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec() runs the code string and defines the function in local_vars\n",
    "local_vars = {}\n",
    "exec(generated_code, {}, local_vars)\n",
    "\n",
    "# Pull out the function by name\n",
    "data_cleaner = local_vars[\"data_cleaner\"]\n",
    "print(f\"Got function: {data_cleaner}\")\n",
    "\n",
    "# Call it on our raw data\n",
    "df_cleaned = data_cleaner(df_raw)\n",
    "\n",
    "print(f\"\\nBefore: {df_raw.shape} -> After: {df_cleaned.shape}\")\n",
    "print(f\"Missing values after cleaning:\\n{df_cleaned.isna().sum()}\")\n",
    "print(f\"Duplicate rows: {df_cleaned.duplicated().sum()}\")\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdr2t21cucv",
   "metadata": {},
   "source": [
    "## Step 6: Now run it all at once through the agent\n",
    "This is equivalent to what `app.py` does — the agent handles steps 2-5 internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fairni3fv9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from data_cleaning_agent import LightweightDataCleaningAgent\n",
    "\n",
    "agent = LightweightDataCleaningAgent(model=llm, log=True, log_path=\"../logs/\")\n",
    "agent.invoke_agent(data_raw=df_raw)\n",
    "\n",
    "df_result = agent.get_data_cleaned()\n",
    "print(f\"Before: {df_raw.shape} -> After: {df_result.shape}\")\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
